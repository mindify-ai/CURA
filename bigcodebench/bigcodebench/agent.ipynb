{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ntuai/ntuai-research/CURA/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_SAMPLES: 1140\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from bigcodebench.data import get_bigcodebench, load_solutions\n",
    "from bigcodebench.data.utils import CACHE_DIR\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "subset = \"full\"  # Replace with your subset name\n",
    "\n",
    "NUM_SAMPLES = len(get_bigcodebench(subset=subset))\n",
    "NUM_CORRECT = 0\n",
    "\n",
    "# Load BigCodeBench dataset and solutions\n",
    "problems = get_bigcodebench(subset=subset)\n",
    "output_file = \"samples.jsonl\"  # Output file for samples\n",
    "\n",
    "# Limit the number of samples to evaluate\n",
    "# problems = dict(list(problems.items())[:NUM_SAMPLES])\n",
    "print(\"NUM_SAMPLES:\", NUM_SAMPLES)\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.95   \n",
    ")\n",
    "\n",
    "llm_reward_model = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.95   \n",
    ")\n",
    "\n",
    "def code_problem_understanding(state: State):\n",
    "    prompt = f\"\"\"\n",
    "    <Identity>\n",
    "    You are an expert AI assistant specializing in programmatic reasoning, problem decomposition, reflective reasoning, and solution verification. Your goal is to deliver clear, logically sound, and testable solutions to complex programming challenges with confidence and precision.\n",
    "    </Identity>\n",
    "    \n",
    "    <Context>\n",
    "    You are provided with a programming problem or codebase that requires a structured approach for analysis and resolution. The process includes breaking the problem into sub-problems, solving each individually, merging solutions, and verifying correctness through testing.\n",
    "    </Context>\n",
    "    \n",
    "    <Task>\n",
    "    {state[\"messages\"]}\n",
    "    </Task>\n",
    "    \n",
    "    <Instructions>\n",
    "    Analyze the problem or codebase and divide it into smaller sub-problems or logical components. Clearly describe each sub-problem, its purpose, and how it contributes to the overall solution. And provide two possible solutions for each sub-problem. \n",
    "    </Instructions>\n",
    "    \n",
    "    <OUTPUT_INSTRUCT>\n",
    "    Please provide two possible solutions for each sub-problem. Please provide the solutions in the following format:\n",
    "    <PLAN_1> Put your first possible solution here with confidence rating from 0 to 10 at <CONFIDENCE_RATING> </CONFIDENCE_RATING> </PLAN_1>\n",
    "    <PLAN_2> Put your second possible solution here with confidence rating from 0 to 10 at <CONFIDENCE_RATING> </CONFIDENCE_RATING> </PLAN_2>\n",
    "    </OUTPUT_INSTRUCT>\n",
    "    \"\"\"\n",
    "\n",
    "    return {\"messages\": [llm.invoke(prompt)]}\n",
    "\n",
    "\n",
    "def code_sol_reasoning(state: State):\n",
    "    prompt = f\"\"\"\n",
    "    <Identity>\n",
    "    You are an expert AI assistant specializing in programmatic reasoning, problem decomposition, reflective reasoning, and solution verification. Your goal is to deliver clear, logically sound, and testable solutions to complex programming challenges with confidence and precision.\n",
    "    </Identity>\n",
    "    \n",
    "    <Context>\n",
    "    You are provided with a programming problem or codebase that requires a structured approach for analysis and resolution. The process include generating the final solution by combining the resolved sub-problems, verifying correctness through testing, and providing the final code solution.\n",
    "    </Context>\n",
    "    \n",
    "    <Task>\n",
    "    {state[\"messages\"]}\n",
    "    </Task>\n",
    "    \n",
    "    <Instructions>\n",
    "    Based on the resolved sub-problems and their solutions, generate the final solution for the problem by combining the resolved sub-problems. Verify the correctness of the final solution through testing and provide the final code solution.\n",
    "    </Instructions>\n",
    "    \n",
    "    <OUTPUT_INSTRUCT>\n",
    "    Please generate two possible solutions for each plan. Please provide the solutions in the following format: \n",
    "    <SOLUTION_1> Put your first possible solution based on the first plan here with confidence rating from 0 to 10 at <CONFIDENCE_RATING> </CONFIDENCE_RATING> </SOLUTION_1>\n",
    "    <SOLUTION_2> Put your second possible solution based on the second plan here with confidence rating from 0 to 10 at <CONFIDENCE_RATING> </CONFIDENCE_RATING> </SOLUTION_2>\n",
    "    </OUTPUT_INSTRUCT>\n",
    "    \n",
    "    <SOLUTION_1>\n",
    "    Put your first possible solution here with confidence rating from 0 to 10 at <CONFIDENCE_RATING> </CONFIDENCE_RATING>\n",
    "    </SOLUTION_1>\n",
    "    \n",
    "    <SOLUTION_2>\n",
    "    Put your second possible solution here with confidence rating from 0 to 10 at <CONFIDENCE_RATING> </CONFIDENCE_RATING>\n",
    "    </SOLUTION_2>\n",
    "    \"\"\"\n",
    "\n",
    "    return {\"messages\": [llm.invoke(prompt)]}\n",
    "\n",
    "def reward_model(state: State):\n",
    "    prompt = f\"\"\"\n",
    "    <Identity>\n",
    "    You are an expert AI assistant specializing in programmatic reasoning, problem decomposition, reflective reasoning, and solution verification. Your goal is to deliver clear, logically sound, and testable solutions to complex programming challenges with confidence and precision.\n",
    "    </Identity>\n",
    "    \n",
    "    <Context>\n",
    "    You are provided with a programming problem or codebase that requires a structured approach for analysis and resolution. The process include generating the final solution by combining the resolved sub-problems, verifying correctness through testing, and providing the final code solution.\n",
    "    </Context>\n",
    "    \n",
    "    <Task>\n",
    "    {state[\"messages\"]}\n",
    "    </Task>\n",
    "    \n",
    "    <Instructions>\n",
    "    Based on the resolved sub-problems and their solutions, generate the final solution for the problem by combining the resolved sub-problems. Verify the correctness of the final solution through testing and provide the final code solution. And provide a score from 0 to 10 for the confidence level of the each final solution.\n",
    "    </Instructions>\n",
    "    \n",
    "    <OUTPUT_INSTRUCT>\n",
    "    Please provide a score from 0 to 10 for the confidence level of the each final solution. Please provide the scores in the following format:\n",
    "    <SOLUTION_1_UNDERSTANDING> Put your confidence score for the first understanding to the solution 1 here </SOLUTION_1_UNDERSTANDING>\n",
    "    <SOLUTION_2_UNDERSTANDING> Put your confidence score for the second understanding to the solution 2 here </SOLUTION_2_UNDERSTANDING>\n",
    "    <SOLUTION_1_REASONING> Put your confidence score for the first reasoning to the solution 1 here </SOLUTION_1_REASONING>\n",
    "    <SOLUTION_2_REASONING> Put your confidence score for the second reasoning to the solution 2 here </SOLUTION_2_REASONING>\n",
    "    <FEEDBACK_1> Provide feedback for the first solution </FEEDBACK_1>\n",
    "    <FEEDBACK_2> Provide feedback for the second solution </FEEDBACK_2>\n",
    "    </OUTPUT_INSTRUCT>\n",
    "    \"\"\"\n",
    "\n",
    "    return {\"messages\": [llm_reward_model.invoke(prompt)]}\n",
    "\n",
    "def routing_condition(state: State):\n",
    "    # If the first solution is not confident, go back to code_sol_reasoning or code_understanding based \n",
    "    if state[\"messages\"][-1].content.find(\"<SOLUTION_1_UNDERSTANDING>\") != -1:\n",
    "        confidence_score = state[\"messages\"][-1].content.split(\"<SOLUTION_1_UNDERSTANDING>\")[1].split(\"</SOLUTION_1_UNDERSTANDING>\")[0]\n",
    "        if int(confidence_score) < 8:\n",
    "            return \"code_problem_understanding\"\n",
    "    # If the second solution is not confident, go back to code_sol_reasoning or code_understanding based\n",
    "    if state[\"messages\"][-1].content.find(\"<SOLUTION_2_UNDERSTANDING>\") != -1:\n",
    "        confidence_score = state[\"messages\"][-1].content.split(\"<SOLUTION_2_UNDERSTANDING>\")[1].split(\"</SOLUTION_2_UNDERSTANDING>\")[0]\n",
    "        if int(confidence_score) < 8:\n",
    "            return \"code_problem_understanding\"\n",
    "    # If the first reasoning is not confident, go back to code_sol_reasoning\n",
    "    if state[\"messages\"][-1].content.find(\"<SOLUTION_1_REASONING>\") != -1:\n",
    "        confidence_score = state[\"messages\"][-1].content.split(\"<SOLUTION_1_REASONING>\")[1].split(\"</SOLUTION_1_REASONING>\")[0]\n",
    "        if int(confidence_score) < 8:\n",
    "            return \"code_solution_reasoning\"\n",
    "    # If the second reasoning is not confident, go back to code_sol_reasoning\n",
    "    if state[\"messages\"][-1].content.find(\"<SOLUTION_2_REASONING>\") != -1:\n",
    "        confidence_score = state[\"messages\"][-1].content.split(\"<SOLUTION_2_REASONING>\")[1].split(\"</SOLUTION_2_REASONING>\")[0]\n",
    "        if int(confidence_score) < 8:\n",
    "            return \"code_solution_reasoning\"\n",
    "\n",
    "    return END\n",
    "\n",
    "graph_builder.add_node(\"code_problem_understanding\", code_problem_understanding)\n",
    "graph_builder.add_node(\"code_solution_reasoning\", code_sol_reasoning)\n",
    "graph_builder.add_node(\"reward_model\", reward_model)\n",
    "graph_builder.set_entry_point(\"code_problem_understanding\")\n",
    "graph_builder.add_edge(\"code_problem_understanding\", \"code_solution_reasoning\")\n",
    "graph_builder.add_edge(\"code_solution_reasoning\", \"reward_model\")\n",
    "graph_builder.add_conditional_edges(\"reward_model\", routing_condition)\n",
    "graph_builder.set_finish_point(\"code_solution_reasoning\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "\"\"\"\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sample generation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Problems:   0%|          | 0/1140 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Task ID: BigCodeBench/0\n",
      "Problem: import itertools\n",
      "from random import shuffle\n",
      "\n",
      "def task_func(numbers=list(range(1, 3))):\n",
      "    \"\"\"\n",
      "    Calculates the average of the sums of absolute differences between each pair of consecutive numbers \n",
      "    for all permutations of a given list. Each permutation is shuffled before calculating the differences.\n",
      "\n",
      "    Args:\n",
      "    - numbers (list): A list of numbers. Default is numbers from 1 to 10.\n",
      "    \n",
      "    Returns:\n",
      "    float: The average of the sums of absolute differences for each shuffled permutation of the list.\n",
      "\n",
      "    Requirements:\n",
      "    - itertools\n",
      "    - random.shuffle\n",
      "\n",
      "    Example:\n",
      "    >>> result = task_func([1, 2, 3])\n",
      "    >>> isinstance(result, float)\n",
      "    True\n",
      "    \"\"\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Problems:   0%|          | 1/1140 [00:41<12:59:38, 41.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Snippet: import itertoolsfrom random import shuffledef task_func(numbers=list(range(1, 11))):  \"\"\"  Calculates the average of the sums of absolute differences between each pair of consecutive numbers   for all permutations of a given list. Each permutation is shuffled before calculating the differences.  Args:  - numbers (list): A list of numbers. Default is numbers from 1 to 10.    Returns:  float: The average of the sums of absolute differences for each shuffled permutation of the list.  Requirements:  - itertools  - random.shuffle  Example:  >>> result = task_func([1, 2, 3])  >>> isinstance(result, float)  True  \"\"\"  def sum_absolute_differences(perm):    # Using zip to create pairs of consecutive elements    return sum(abs(a - b) for a, b in zip(perm, perm[1:]))  # Generate all permutations  permutations = list(itertools.permutations(numbers))  total_sum = 0  count = 0  # Shuffle each permutation and calculate the absolute differences  for perm in permutations:    shuffled_perm = list(perm) # Copy the permutation    shuffle(shuffled_perm)    # Shuffle the copied permutation    total_sum += sum_absolute_differences(shuffled_perm)    count += 1  # Calculate average  return total_sum / count if count > 0 else 0# Testing the function with sample dataresult = task_func([1, 2, 3])print(f\"Result: {result:.2f}\") # Output should be a float representation\n",
      "--------------------\n",
      "Task ID: BigCodeBench/1\n",
      "Problem: import collections\n",
      "import random\n",
      "import string\n",
      "\n",
      "def task_func(length=100):\n",
      "    \"\"\"\n",
      "    Generate a random string of the specified length composed of uppercase and lowercase letters, \n",
      "    and then count the occurrence of each character in this string.\n",
      "\n",
      "    Parameters:\n",
      "    length (int, optional): The number of characters in the generated string. Default is 100.\n",
      "\n",
      "    Returns:\n",
      "    dict: A dictionary where each key is a character from the generated string and the value \n",
      "            is the count of how many times that character appears in the string.\n",
      "\n",
      "    Requirements:\n",
      "    - collections\n",
      "    - random\n",
      "    - string\n",
      "\n",
      "    Raises:\n",
      "    ValueError if the length is a negative number\n",
      "\n",
      "    Example:\n",
      "    >>> import random\n",
      "    >>> random.seed(42)  # Ensures reproducibility for demonstration\n",
      "    >>> task_func(10)\n",
      "    {'h': 1, 'B': 2, 'O': 1, 'L': 1, 'm': 1, 'j': 1, 'u': 1, 'E': 1, 'V': 1}\n",
      "    \"\"\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Problems:   0%|          | 2/1140 [01:06<10:00:40, 31.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Snippet: import collectionsimport randomimport stringdef task_func(length=100):  \"\"\"  Generate a random string of the specified length composed of uppercase and lowercase letters,   and then count the occurrence of each character in this string.  Parameters:  length (int, optional): The number of characters in the generated string. Default is 100.  Returns:  dict: A dictionary where each key is a character from the generated string and the value      is the count of how many times that character appears in the string.  Requirements:  - collections  - random  - string  Raises:  ValueError if the length is a negative number  Example:  >>> import random  >>> random.seed(42) # Ensures reproducibility for demonstration  >>> task_func(10)  {'h': 1, 'B': 2, 'O': 1, 'L': 1, 'm': 1, 'j': 1, 'u': 1, 'E': 1, 'V': 1}  \"\"\"    # Sub-Problem 1: Validate the Input Length  if length < 0:    raise ValueError(\"Length must be a non-negative integer.\")    # Sub-Problem 2: Generate a Random String  characters = string.ascii_letters  random_string = ''.join(random.choices(characters, k=length))    # Sub-Problem 3: Count Character Occurrences  return dict(collections.Counter(random_string))# Verification through testingif __name__ == \"__main__\":  # Test with a normal length  print(task_func(10)) # Example output    # Test with length 0  print(task_func(0))  # Should return an empty dictionary {}    # Test with a negative length  try:    print(task_func(-5)) # Should raise a ValueError  except ValueError as e:    print(e)\n",
      "--------------------\n",
      "Task ID: BigCodeBench/2\n",
      "Problem: import random\n",
      "import statistics\n",
      "\n",
      "def task_func(LETTERS):\n",
      "    \"\"\"\n",
      "    Create a dictionary in which keys are random letters and values are lists of random integers.\n",
      "    The dictionary is then sorted by the mean of the values in descending order, demonstrating the use of the statistics library.\n",
      "    \n",
      "    Parameters:\n",
      "        LETTERS (list of str): A list of characters used as keys for the dictionary.\n",
      "    \n",
      "    Returns:\n",
      "    dict: The sorted dictionary with letters as keys and lists of integers as values, sorted by their mean values.\n",
      "    \n",
      "    Requirements:\n",
      "    - random\n",
      "    - statistics\n",
      "    \n",
      "    Example:\n",
      "    >>> import random\n",
      "    >>> random.seed(42)\n",
      "    >>> sorted_dict = task_func(['a', 'b', 'c'])\n",
      "    >>> list(sorted_dict.keys())\n",
      "    ['a', 'b', 'c']\n",
      "    >>> isinstance(sorted_dict['a'], list)\n",
      "    True\n",
      "    >>> type(sorted_dict['a'])  # Check type of values\n",
      "    <class 'list'>\n",
      "    \"\"\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Problems:   0%|          | 3/1140 [01:41<10:29:05, 33.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Snippet: import randomimport statisticsdef task_func(LETTERS):  def generate_random_list():    return [random.randint(1, 100) for _ in range(10)]  # Create the dictionary  letter_to_numbers = {letter: generate_random_list() for letter in LETTERS}  # Sort the dictionary by the mean of the lists in descending order  sorted_dict = dict(sorted(letter_to_numbers.items(), key=lambda item: statistics.mean(item[1]), reverse=True))  return sorted_dict# Testing the functionif __name__ == \"__main__\":  random.seed(42) # Seed for reproducibility  sorted_dict = task_func(['a', 'b', 'c'])  print(sorted_dict) # The output should show the dictionary with letters sorted by mean values  print(list(sorted_dict.keys())) # Should output the keys in sorted order  print(isinstance(sorted_dict['a'], list)) # Check if value is a list  print(type(sorted_dict['a'])) # Check the type of the value\n",
      "--------------------\n",
      "Task ID: BigCodeBench/3\n",
      "Problem: import random\n",
      "import numpy as np\n",
      "\n",
      "def task_func(LETTERS):\n",
      "    \"\"\"\n",
      "    Create a dictionary where keys are specified letters and values are lists of random integers.\n",
      "    Then calculate the mean of these integers for each key and return a dictionary of these means.\n",
      "\n",
      "    Parameters:\n",
      "        LETTERS (list of str): List of single-character strings to be used as keys in the output dictionary.\n",
      "    \n",
      "    Returns:\n",
      "        dict: A dictionary where each key is a letter from the input list and the value is the mean of \n",
      "              a randomly generated list of integers (with each list having 1 to 10 integers ranging from 0 to 100).\n",
      "    \n",
      "    Requirements:\n",
      "    - random\n",
      "    - np (numpy)\n",
      "    \n",
      "    Example:\n",
      "    >>> LETTERS = ['a', 'b', 'c']\n",
      "    >>> mean_dict = task_func(LETTERS)\n",
      "    >>> isinstance(mean_dict, dict)\n",
      "    True\n",
      "    >>> 'a' in mean_dict.keys() and 'b' in mean_dict.keys() and 'c' in mean_dict.keys()\n",
      "    True\n",
      "    >>> all(isinstance(v, float) for v in mean_dict.values())  # Check if all values are floats\n",
      "    True\n",
      "    \"\"\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Problems:   0%|          | 4/1140 [02:19<11:07:15, 35.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Snippet: import randomimport numpy as npdef task_func(LETTERS):  \"\"\"  Create a dictionary where keys are specified letters and values are lists of random integers.  Then calculate the mean of these integers for each key and return a dictionary of these means.  Parameters:    LETTERS (list of str): List of single-character strings to be used as keys in the output dictionary.    Returns:    dict: A dictionary where each key is a letter from the input list and the value is the mean of        a randomly generated list of integers (with each list having 1 to 10 integers ranging from 0 to 100).    Requirements:  - random  - np (numpy)    Example:  >>> LETTERS = ['a', 'b', 'c']  >>> mean_dict = task_func(LETTERS)  >>> isinstance(mean_dict, dict)  True  >>> 'a' in mean_dict.keys() and 'b' in mean_dict.keys() and 'c' in mean_dict.keys()  True  >>> all(isinstance(v, float) for v in mean_dict.values()) # Check if all values are floats  True  \"\"\"    # Sub-problem 1: Generate random integers for each letter  random_dict = {letter: [random.randint(0, 100) for _ in range(random.randint(1, 10))] for letter in LETTERS}    # Sub-problem 2: Calculate means  mean_dict = {letter: np.mean(values) for letter, values in random_dict.items()}    return mean_dict\n",
      "--------------------\n",
      "Task ID: BigCodeBench/4\n",
      "Problem: from collections import Counter\n",
      "import itertools\n",
      "\n",
      "def task_func(d):\n",
      "    \"\"\"\n",
      "    Count the occurrence of each integer in the values of the input dictionary, where each value is a list of integers,\n",
      "    and return a dictionary with these counts. The resulting dictionary's keys are the integers, and the values are \n",
      "    their respective counts across all lists in the input dictionary.\n",
      "\n",
      "    Parameters:\n",
      "    d (dict): A dictionary where each key is a string and the value is a list of integers.\n",
      "\n",
      "    Returns:\n",
      "    dict: A dictionary where each key is an integer from any of the input lists, and the value is the count of \n",
      "            how often that integer appears in all the lists combined.\n",
      "\n",
      "    Requirements:\n",
      "    - collections.Counter\n",
      "    - itertools\n",
      "    \n",
      "    Example:\n",
      "    >>> d = {'a': [1, 2, 3, 1], 'b': [3, 4, 5], 'c': [1, 2]}\n",
      "    >>> count_dict = task_func(d)\n",
      "    >>> print(count_dict)\n",
      "    {1: 3, 2: 2, 3: 2, 4: 1, 5: 1}\n",
      "    \"\"\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Problems:   0%|          | 5/1140 [02:41<9:35:49, 30.44s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Snippet: from collections import Counter   def task_func(d):    # Step 1: Extract all integers from lists in the dictionary    all_integers = [num for sublist in d.values() for num in sublist]       # Step 2: Count occurrences of each integer using Counter    integer_counts = Counter(all_integers)       # Return the result as a dictionary    return dict(integer_counts)  # Example usage  d = {'a': [1, 2, 3, 1], 'b': [3, 4, 5], 'c': [1, 2]}  count_dict = task_func(d)  print(count_dict) # Output: {1: 3, 2: 2, 3: 2, 4: 1, 5: 1}\n",
      "--------------------\n",
      "Task ID: BigCodeBench/5\n",
      "Problem: import random\n",
      "import math\n",
      "\n",
      "def task_func(LETTERS=[chr(i) for i in range(97, 123)]):\n",
      "    \"\"\"\n",
      "    Create a dictionary where keys are letters from a predefined list LETTERS and values are lists of random integers.\n",
      "    Then, calculates the population standard deviation for each list of integers and returns a dictionary of these values.\n",
      "\n",
      "    The random integers for each key are generated within the range 0 to 100, and each list contains between 1 to 10 integers.\n",
      "\n",
      "    Parameters:\n",
      "        LETTERS (list of str, optional): A list of single-character strings to be used as keys in the output dictionary.\n",
      "                                         Defaults to the lowercase English alphabets ['a', 'b', ..., 'z'].\n",
      "\n",
      "    Returns:\n",
      "        dict: A dictionary where each key corresponds to a letter from the input list and each value is the \n",
      "              population standard deviation of a list of random integers associated with that key.\n",
      "\n",
      "    Requirements:\n",
      "    - random\n",
      "    - math\n",
      "\n",
      "    Example:\n",
      "    >>> import random\n",
      "    >>> random.seed(42)\n",
      "    >>> sd_dict = task_func()\n",
      "    >>> print(sd_dict)\n",
      "    {'a': 45.5, 'b': 29.4659125092029, 'c': 25.575354649194974, 'd': 28.271717316074028, 'e': 29.118550788114437, 'f': 16.886056048968, 'g': 27.48108440364026, 'h': 32.67476090195611, 'i': 8.5, 'j': 17.5406234036238, 'k': 22.993205518152532, 'l': 2.0, 'm': 25.468935326524086, 'n': 10.23067283548187, 'o': 35.13922924736349, 'p': 26.649654437396617, 'q': 27.027763503479157, 'r': 20.316629447296748, 's': 24.997777679003566, 't': 0.0, 'u': 30.070288030250428, 'v': 21.82864622275892, 'w': 37.92308004368844, 'x': 29.899006961502092, 'y': 33.89321466016465, 'z': 21.0}\n",
      "    \"\"\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Problems:   1%|          | 6/1140 [03:05<8:51:14, 28.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Snippet: <SOLUTION_1_UNDERSTANDING>10</SOLUTION_1_UNDERSTANDING><SOLUTION_2_UNDERSTANDING>9</SOLUTION_2_UNDERSTANDING><SOLUTION_1_REASONING>10</SOLUTION_1_REASONING><SOLUTION_2_REASONING>9</SOLUTION_2_REASONING><FEEDBACK_1>The first solution is complete and relies on Python's built-in library for calculating the population standard deviation, which is efficient and concise. The implementation correctly achieves the intended functionality as described in the prompt.</FEEDBACK_1><FEEDBACK_2>The second solution also correctly implements the required functionality, but it manually calculates the population standard deviation, which is less efficient than using the built-in library. While it demonstrates a good understanding of the underlying concepts, using built-in functions can reduce complexity and potential errors. Overall, both solutions are valid but the first one is preferable for simplicity and performance.</FEEDBACK_2>\n",
      "--------------------\n",
      "Task ID: BigCodeBench/6\n",
      "Problem: import os\n",
      "import re\n",
      "\n",
      "def task_func(pattern, log_dir='/var/log/'):\n",
      "    \"\"\"\n",
      "    Find the latest log file in a specified directory that matches a given regex pattern.\n",
      "\n",
      "    This function searches through all files in the specified directory, filters them based on the provided regex pattern, \n",
      "    and returns the path to the most recent log file based on modification time. If no files match the pattern or the directory \n",
      "    is empty, the function returns None.\n",
      "\n",
      "    Parameters:\n",
      "        pattern (str): The regex pattern to match the names of the log files.\n",
      "        log_dir (str, optional): The directory to search for log files. Defaults to '/var/log/'.\n",
      "\n",
      "    Returns:\n",
      "        str or None: The path to the most recent log file that matches the pattern, or None if no matching files are found.\n",
      "\n",
      "    Requirements:\n",
      "    - os\n",
      "    - re\n",
      "\n",
      "    Example:\n",
      "    >>> task_func(r'^access.log.[0-9]+$', '/var/log/')\n",
      "    '/var/log/access.log.1234'\n",
      "    \"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure cache directory exists\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting sample generation...\")\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for i, (task_id, problem) in enumerate(\n",
    "            tqdm(problems.items(), desc=\"Processing Problems\")\n",
    "        ):\n",
    "            if i >= NUM_SAMPLES:\n",
    "                break\n",
    "\n",
    "            print(\"--------------------\")\n",
    "            print(f\"Task ID: {task_id}\")\n",
    "            print(\"Problem:\", problem[\"complete_prompt\"])\n",
    "\n",
    "            if not problem:\n",
    "                print(f\"Problem with task ID {task_id} not found in the dataset.\")\n",
    "                continue\n",
    "\n",
    "            # Construct the state object\n",
    "            state = {\n",
    "                \"messages\": problem[\"complete_prompt\"]\n",
    "                + \" based on the instruction: \"\n",
    "                + problem[\"instruct_prompt\"]\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                # Generate response using the graph\n",
    "                answer = graph.invoke(state)\n",
    "                \n",
    "                answer_snippet = (\n",
    "                    str(answer[\"messages\"][-1].content)\n",
    "                    .strip()\n",
    "                    .replace(\"\\n\", \"\")\n",
    "                    .replace(\"  \", \" \")\n",
    "                )\n",
    "\n",
    "                # Extract Python code if present\n",
    "                if \"```python\" in answer_snippet:\n",
    "                    answer_snippet = (\n",
    "                        answer_snippet.split(\"```python\")[1].split(\"```\")[0].strip()\n",
    "                    )\n",
    "\n",
    "                print(\"Answer Snippet:\", answer_snippet)\n",
    "\n",
    "                # Prepare JSON object\n",
    "                sample = {\n",
    "                    \"task_id\": task_id,\n",
    "                    \"solution\": answer_snippet,\n",
    "                    \"completion\": answer_snippet,\n",
    "                    \"instruction_prompt\": problem[\"instruct_prompt\"],\n",
    "                    \"test_prompt\": problem[\"test\"],\n",
    "                }\n",
    "\n",
    "                # Write to JSONL file\n",
    "                f.write(json.dumps(sample) + \"\\n\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing Task ID {task_id}: {e}\")\n",
    "\n",
    "    print(f\"Sample generation completed. Output saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
